{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Create by Honk 3/2/2023\n"
      ],
      "metadata": {
        "id": "c469e0nlof5y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS1b7oF5oc71",
        "outputId": "be9a55b9-4350-4aed-ce6a-4d9ccd2305e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-12.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.0 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-12.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytube"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3aZkJADoqie",
        "outputId": "70a5f8c7-df0c-44c5-ef22-7d9059743a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20230124.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai-whisper) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from openai-whisper) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai-whisper) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from openai-whisper) (9.0.0)\n",
            "Collecting transformers>=4.19.0\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->openai-whisper) (0.16.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->openai-whisper) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper) (2022.12.7)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230124-py3-none-any.whl size=1179329 sha256=de955db5251c090635daf000a6a4ba075e43d890837fae974522ea6db748f91e\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/c2/dd/8639c7cda1e20412e499ab65e5003d8863ef8622792ea26446\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tokenizers, ffmpeg-python, huggingface-hub, transformers, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.12.1 openai-whisper-20230124 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yt_url = \"https://www.youtube.com/watch?v=nAR2w5xZ2XY&ab_channel=Rti%E4%B8%AD%E5%A4%AE%E5%BB%A3%E6%92%AD%E9%9B%BB%E8%87%BA\""
      ],
      "metadata": {
        "id": "JzuyidJjpAV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube"
      ],
      "metadata": {
        "id": "K0T8ucEbpZI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yt = YouTube(yt_url)\n",
        "yt.streams.filter().get_audio_only().download(filename='test.mp3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "86fsRZSMplJc",
        "outputId": "6b5c85a8-440c-4ce1-cc01-a5afd10c2148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/test.mp3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper test.mp3 --device cuda --model large --language Chinese --initial_prompt \"以下為繁體中文逐字稿\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLOsPSx6pq9s",
        "outputId": "5ef930b2-1ce4-4cab-f505-5e36fd28cb2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-02 09:33:11.128943: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-02 09:33:12.352797: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-02 09:33:12.352905: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-02 09:33:12.352924: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/usr/local/lib/python3.8/dist-packages/whisper/__init__.py:48: UserWarning: /root/.cache/whisper/large-v2.pt exists, but the SHA256 checksum does not match; re-downloading the file\n",
            "  warnings.warn(f\"{download_target} exists, but the SHA256 checksum does not match; re-downloading the file\")\n",
            "100%|██████████████████████████████████████| 2.87G/2.87G [00:18<00:00, 163MiB/s]\n",
            "[00:00.000 --> 00:08.000] 傳國中兵同胞們,傳世界愛好和平的兄弟們\n",
            "[00:08.000 --> 00:16.000] 今天我們經歷了經歷必然辛苦揚捲的經歷\n",
            "[00:16.000 --> 00:20.000] 終於達到了它最後的經歷\n",
            "[00:20.000 --> 00:27.000] 也就是標誌了我們國民革命歷史實名的進攻\n",
            "[00:27.000 --> 00:36.000] 我們中國在海岸和西方的這一種百年奮鬥的心意\n",
            "[00:36.000 --> 00:39.000] 今天才達到了實現\n",
            "[00:39.000 --> 00:44.000] 我們對於現已在我們面前的世界和平\n",
            "[00:44.000 --> 00:51.000] 要感謝我們穿過抗戰以來縱容犧牲的中兵協力\n",
            "[00:51.000 --> 00:56.000] 要感謝我們為經歷和平而共同主張的盟友\n",
            "[00:56.000 --> 01:04.000] 也是感謝我們辜負辛苦艱難領導我們革命進出的道路\n",
            "[01:04.000 --> 01:08.000] 是我們對於今天心裡的一天\n",
            "[01:08.000 --> 01:16.000] 而全世界的基督徒更要一致感謝我們恭敬而聳之的上帝\n",
            "[01:16.000 --> 01:23.000] 我傳國中兵同胞們自抗戰以來\n",
            "[01:23.000 --> 01:27.000] 百年前所有的痛苦和犧牲\n",
            "[01:27.000 --> 01:30.000] 甚至一年一年的增加\n",
            "[01:30.000 --> 01:33.000] 和抗戰必經的信念\n",
            "[01:33.000 --> 01:36.000] 也是一天一天地加強\n",
            "[01:36.000 --> 01:40.000] 尤其是我們冷野區的同胞們\n",
            "[01:40.000 --> 01:46.000] 修建了無用殘骸和懦弱的河岸\n",
            "[01:46.000 --> 01:54.000] 今天是達到了完善解放而重建青天白雪了\n",
            "[01:54.000 --> 02:00.000] 這幾天以來各地中兵的歡呼和快活的情日\n",
            "[02:00.000 --> 02:09.000] 只要一年也就是為了北戰領區同胞和大寮解放\n",
            "[02:09.000 --> 02:12.000] 現在我們抗戰成立了\n",
            "[02:12.000 --> 02:16.000] 這還不能算是最後的行禮\n",
            "[02:16.000 --> 02:19.000] 是我們戰勝的涵義\n",
            "[02:19.000 --> 02:26.000] 絕不只是在世界公民力量又大了一次新增的一天上\n",
            "[02:26.000 --> 02:31.000] 我相信全世界人類和我們全國同胞們\n",
            "[02:31.000 --> 02:36.000] 都一定在希望著這次戰爭\n",
            "[02:36.000 --> 02:41.000] 是世界文明國家所參加的最後一次的戰爭\n",
            "[02:41.000 --> 02:43.000] 謝謝\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r2BZwu7nqo0C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}